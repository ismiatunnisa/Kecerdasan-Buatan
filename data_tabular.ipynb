{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data tabular(tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data tabel(tabular)\n",
    "data_raw = pd.read_csv('dataset/titanic.csv')\n",
    "data_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 892,  893,  894,  895,  896,  897,  898,  899,  900,  901,  902,\n",
       "        903,  904,  905,  906,  907,  908,  909,  910,  911,  912,  913,\n",
       "        914,  915,  916,  917,  918,  919,  920,  921,  922,  923,  924,\n",
       "        925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
       "        936,  937,  938,  939,  940,  941,  942,  943,  944,  945,  946,\n",
       "        947,  948,  949,  950,  951,  952,  953,  954,  955,  956,  957,\n",
       "        958,  959,  960,  961,  962,  963,  964,  965,  966,  967,  968,\n",
       "        969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
       "        980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,\n",
       "        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001,\n",
       "       1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012,\n",
       "       1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023,\n",
       "       1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034,\n",
       "       1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045,\n",
       "       1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056,\n",
       "       1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067,\n",
       "       1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078,\n",
       "       1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089,\n",
       "       1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100,\n",
       "       1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111,\n",
       "       1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122,\n",
       "       1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133,\n",
       "       1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144,\n",
       "       1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155,\n",
       "       1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166,\n",
       "       1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177,\n",
       "       1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188,\n",
       "       1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,\n",
       "       1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210,\n",
       "       1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221,\n",
       "       1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232,\n",
       "       1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243,\n",
       "       1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254,\n",
       "       1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265,\n",
       "       1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276,\n",
       "       1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287,\n",
       "       1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298,\n",
       "       1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw['PassengerId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_raw['PassengerId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_y = ['Survived']\n",
    "column_x = ['Pclass','Sex', 'Age', 'Embarked', 'SibSp', 'Fare', 'Parch' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#endcoder(mengubah object menjadi int)\n",
    "#bikin alat\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "x_train['Sex']= encoder.fit_transform(x_train[['Sex']])\n",
    "x_test['Sex']= encoder.fit_transform(x_test[['Sex']])\n",
    "\n",
    "\n",
    "x_train['Embarked']= encoder.fit_transform(x_train[['Embarked']])\n",
    "x_test['Embarked']= encoder.fit_transform(x_test[['Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#membagi dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_raw[column_x], data_raw[column_y],\n",
    "    test_size=.2\n",
    ")\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELING\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=[7]),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    #kelasnya ada 2 jadi pakai sigmoid\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#konfigurasi\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6138\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 798us/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 898us/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 998us/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22fb7c72890>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data text\n",
    "import urllib\n",
    "import json\n",
    "data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sarcasm.json'\n",
    "urllib.request.urlretrieve(data_url, 'sarcasm.json')\n",
    "with open(\"sarcasm.json\", 'r') as file: dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sarcasm = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarcasm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc cara mengambil data dari dataframe\n",
    "data_used = df_sarcasm.iloc[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"former versace store clerk sues over secret 'black code' for minority shoppers\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_used['headline'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0688a561721c1d45ed17f12f7ca1d463e3643a56cc5dac145b94456e634fc76d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
